{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aramis/mood-diary?scriptVersionId=235023627\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Project Introduction: MoodBot - Your AI-Powered Mood and Quote Companion\n\n* Debajyoti Nag\n* April 2025\n* Jakarta, Indonesia\n\nMoodBot is a unique AI-driven project designed to enhance your personal journaling experience. At its core, MoodBot is a conversational agent that interacts with you to log your daily moods, provide supportive quotes, and allow you to reflect on your emotional history.\n\nKey Features and Functionalities:\n\n* Mood Logging: MoodBot allows you to easily record your daily mood, along with a corresponding emoji and a relevant, encouraging quote. This information is stored for future reference and analysis.\n\n* Mood History Retrieval: You can ask MoodBot about your past moods using natural language. The bot is designed to understand a variety of queries, including those with specific dates or general timeframes (e.g., \"How was I feeling yesterday?\", \"Tell me about my moods from last week.\").\n\n* Conversational Interaction: MoodBot engages in a friendly and supportive conversation. It acknowledges your entries, provides encouragement, and responds to your queries in a clear and understandable manner.\n\n* Langchain Integration: The project leverages Langchain to create a dynamic conversational flow, enabling the bot to process user input, determine the appropriate action (logging mood or querying history), and generate coherent responses.\n\n* ChromaDB Integration: The mood logs, quotes, and timestamps are stored in a ChromaDB vector store.  This allows for efficient retrieval of mood history using semantic search, enabling the bot to understand the meaning of your queries, even if they don't contain exact dates.\n\n* Gemini LLM: The project uses the Gemini LLM  to generate supportive quotes, understand the nuances of user queries, and craft natural-sounding responses.\n\nHow it Works:\n\n* Mood Logging: When you tell MoodBot how you are feeling, the bot extracts your mood, suggests an emoji, retrieves a quote, and stores this information with a timestamp in ChromaDB.\n\n* Mood History Querying: When you ask about your mood history, the bot uses the Gemini LLM to understand the intent and time frame of your query.  It then retrieves relevant entries from ChromaDB using semantic search and provides you with a conversational summary of your past moods.\n\nPotential Benefits:\n\n* Enhanced Self-Reflection: By logging your moods and reflecting on past entries, you can gain valuable insights into your emotional patterns and triggers.\n\n* Improved Mood Tracking: MoodBot provides a convenient and engaging way to track your mood over time.\n\n* Personalized Support: The supportive quotes and conversational nature of the bot can provide a sense of personalized support and encouragement.\n\n\nGen AI capabilities showcased:\n\n* Few-shot prompting\n* Function Calling\n* Agents\n* Embeddings\n* Retrieval augmented generation (RAG)\n* Grounding (optional, for the quotes)\n","metadata":{}},{"cell_type":"markdown","source":"First, to set up all needed packages and imports. \n\nReferences: \n* 5-Day Gen AI Intensive course: https://www.kaggle.com/learn-guide/5-day-genai\n* LAngchain tutorials: https://langchain-ai.github.io/langgraph/tutorials/\n* ChromaDB Docs: https://docs.trychroma.com/getting-started\n","metadata":{}},{"cell_type":"code","source":"# Remove unused packages from Kaggle's base image that conflict\n#!pip uninstall -qqy jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n\n#install needed packages\n!pip install -U -q \"google-genai==1.7.0\" \"langgraph==0.3.21\" \"langchain-google-genai==2.1.2\" \"langgraph-prebuilt==0.1.7\"  \"chromadb==0.6.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:39:40.954259Z","iopub.execute_input":"2025-04-19T09:39:40.954553Z","iopub.status.idle":"2025-04-19T09:40:31.973594Z","shell.execute_reply.started":"2025-04-19T09:39:40.954533Z","shell.execute_reply":"2025-04-19T09:40:31.972269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Generic\nimport os\nimport PIL \nfrom typing import TypedDict, List, Dict, Optional, Any, Literal, Annotated\nfrom typing_extensions import TypedDict  \nimport numpy as np\nimport pandas as pd\nfrom google import genai\nfrom google.genai import types\nfrom google.api_core import retry\nfrom kaggle_secrets import UserSecretsClient\n\n### for langchain and visualising the graphs\nfrom langchain_core.messages.ai import AIMessage\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages  # Correct import\nfrom IPython.display import HTML, Markdown, display, Image\n\n### for langgraph tools\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import ToolNode\n\n\n\n### for chromadb, datetime\nfrom chromadb import chromadb, Documents, EmbeddingFunction, Embeddings\nfrom datetime import datetime\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:31.976091Z","iopub.execute_input":"2025-04-19T09:40:31.976475Z","iopub.status.idle":"2025-04-19T09:40:35.536215Z","shell.execute_reply.started":"2025-04-19T09:40:31.976441Z","shell.execute_reply":"2025-04-19T09:40:35.535283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up gemini API key and make it retriable. \n\nThis was one of the first concepts taught during day 1 of the 5-day intensive course.","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\n\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:35.537348Z","iopub.execute_input":"2025-04-19T09:40:35.537984Z","iopub.status.idle":"2025-04-19T09:40:36.184621Z","shell.execute_reply.started":"2025-04-19T09:40:35.53795Z","shell.execute_reply":"2025-04-19T09:40:36.183711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langgraph.checkpoint.memory import MemorySaver\n\n# Create a MemorySaver\nmemory = MemorySaver()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.186882Z","iopub.execute_input":"2025-04-19T09:40:36.18717Z","iopub.status.idle":"2025-04-19T09:40:36.194069Z","shell.execute_reply.started":"2025-04-19T09:40:36.187151Z","shell.execute_reply":"2025-04-19T09:40:36.193006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Define the core system and system instructions for the Diarybot\n### For this, I decided to build upon the baristabot example instead of writing from scratch\n\nclass DiaryBotState(TypedDict):\n    \"\"\"State representing the NeutriBot conversation and tasks.\"\"\"\n\n    messages: Annotated[list, add_messages]\n\n    # The customer's in-progress order.\n    order: list[str]    \n    \n    # Flag indicating that the order is placed and completed.\n    finished: bool\n\n\n# The system instruction defines how the chatbot is expected to behave and includes\n# rules for when to call different functions, as well as rules for the conversation, such\n# as tone and what is permitted for discussion.\nDIARYBOT_SYSINT = (\n    \"system\", # Indicates the message is a system instruction.\n    \"You are DiaryBot, a personal journaling assistant designed to help users track their daily feelings and offer uplifting support. \"\n    \"Your primary goals are to ask the user about their current mood, generate a relevant emoji representing that mood \"\n    \"provide an encouraging quote (ideally grounded in a known source), and optionally store this information.\"\n    \"\\n\\n\"\n    \"**Core Workflow:**\"\n    \"1.  **Prompt for Mood:** At the beginning of each interaction, ask the user 'How are you feeling today?' or a similar open-ended question about their mood.\"\n    \"2.  **Analyze Mood:** Based on the user's response, identify the sentiment expressed (e.g., happy, sad, angry, neutral, excited).\"\n    \"3.  **Generate Emoji:** Select an appropriate emoji that best represents the user's stated mood.\"\n    \"4.  **Generate Uplifting Quote:** Find a relevant and encouraging quote. If possible, try to recall or access a known source for the quote (e.g., a famous author, historical figure, or well-known saying). If grounding is not directly feasible with your current capabilities, provide a generally positive and relevant quote.\"\n    \"5.  **Present Emoji and Quote:** Show the generated emoji and the uplifting quote to the user. If you have a source for the quote, include it (e.g., 'ðŸ˜Š Here's a little something for you: 'The only way to do great work is to love what you do.' - Steve Jobs').\"\n    \"6.  **Optional Logging:** Offer the user the option to save their mood, the emoji, and the quote. For example: 'Would you like me to save your feeling, the emoji, and this quote for today?'\"\n    \"7.  **Log Mood and Quote (if requested):** If the user agrees, use the `log_mood_with_quote` tool to save the mood description, generated emoji, the quote, and the current timestamp to the user's local diary database.\"\n    \"\\n\\n\"\n    \"**Additional Functions:**\"\n    \"\\n* **Query History:** Users can ask about their past moods and associated quotes (e.g., 'How was I feeling yesterday and what was the quote?', 'Show me my moods and quotes from last week'). Use the `query_mood_history_with_quote` tool to retrieve and present this information from the local database (including the date, time, mood description, emoji, and quote).\"\n    \"\\n\\n\"\n    \"**Interaction Guidelines:**\"\n    \"\\n* Be friendly and encouraging.\"\n    \"\\n* Focus solely on capturing and (optionally) logging the user's mood, generating an emoji and a quote, and related history retrieval.\"\n    \"\\n* If the user's mood description is ambiguous, you can ask for clarification (e.g., 'Could you tell me a little more about how you're feeling?').\"\n    \"\\n* Respect the user's choice if they do not want to log their mood and quote.\"\n    \"\\n* Aim for relevant and genuinely uplifting quotes.\"\n    \"\\n\\n\"\n    \"**Tool Usage Summary:**\"\n    \"\\n* `log_mood_with_quote(mood_description, emoji, quote, date_time)`: Call this *after* generating the emoji and quote and receiving confirmation from the user to save the mood entry.\"\n    \"\\n* `query_mood_history_with_quote(query_details)`: Call this when the user asks about their past moods and associated quotes.\"\n    \"\\n\\n\"\n    \"If any required tools are unavailable or fail, inform the user clearly that the specific function (like logging with a quote or querying history with quotes) cannot be performed at this time.\"\n)\n\nWELCOME_MSG = \"Hello! How are you feeling today?\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.195107Z","iopub.execute_input":"2025-04-19T09:40:36.195443Z","iopub.status.idle":"2025-04-19T09:40:36.248595Z","shell.execute_reply.started":"2025-04-19T09:40:36.195411Z","shell.execute_reply":"2025-04-19T09:40:36.247469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Define human node\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n\ndef human_node(state: DiaryBotState) -> DiaryBotState:\n    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n    last_msg = state[\"messages\"][-1]\n    print(\"Model:\", last_msg.content)\n\n    user_input = input(\"User: \")\n\n    # If it looks like the user is trying to quit, flag the conversation\n    # as over.\n    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n        state[\"finished\"] = True\n\n    return state | {\"messages\": [(\"user\", user_input)]}\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.249738Z","iopub.execute_input":"2025-04-19T09:40:36.250068Z","iopub.status.idle":"2025-04-19T09:40:36.309289Z","shell.execute_reply.started":"2025-04-19T09:40:36.250041Z","shell.execute_reply":"2025-04-19T09:40:36.308326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# chatbot with welcome message, this one will be given access to tools and is not the final version.\n##No need to run every time.\n\n### Uncomment below to run\n\n#def chatbot_with_welcome_msg(state: DiaryBotState) -> DiaryBotState:\n#    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n#\n#    if state[\"messages\"]:\n#        # If there are messages, continue the conversation with the Gemini model.\n#        new_output = llm.invoke([DIARYBOT_SYSINT] + state[\"messages\"])\n#    else:\n#        # If there are no messages, start with the welcome message.\n#        new_output = AIMessage(content=WELCOME_MSG)\n#\n#    return state | {\"messages\": [new_output]}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.310371Z","iopub.execute_input":"2025-04-19T09:40:36.310695Z","iopub.status.idle":"2025-04-19T09:40:36.316133Z","shell.execute_reply.started":"2025-04-19T09:40:36.310659Z","shell.execute_reply":"2025-04-19T09:40:36.315004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Custom function for chromadb\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents, or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.31725Z","iopub.execute_input":"2025-04-19T09:40:36.317568Z","iopub.status.idle":"2025-04-19T09:40:36.343018Z","shell.execute_reply.started":"2025-04-19T09:40:36.317544Z","shell.execute_reply":"2025-04-19T09:40:36.341932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DB_NAME = \"DiaryBotdb\"\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\n#db.count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.343933Z","iopub.execute_input":"2025-04-19T09:40:36.344241Z","iopub.status.idle":"2025-04-19T09:40:36.771204Z","shell.execute_reply.started":"2025-04-19T09:40:36.344221Z","shell.execute_reply":"2025-04-19T09:40:36.770258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from langchain_core.tools import tool\n\n\n@tool\ndef log_mood_with_quote(mood_description: str, emoji: str, quote: str):\n    \"\"\"Logs the mood, emoji, and quote to ChromaDB.\"\"\"\n    #date_time = datetime.now().isoformat()\n\n    document = f\"Mood: {mood_description}\\nEmoji: {emoji}\\nQuote: {quote}\\nTimestamp: {datetime.now().isoformat()}\"\n\n    db.add(  # Use the 'db' object here, which represents your 'googlecardb' collection\n        documents=[document],\n        ids=[f\"mood_log_{datetime.now().isoformat()}\"]  # Unique ID for each entry\n    )\n    print(f\"Mood logged successfully to '{DB_NAME}': {document}\")\n    return \"Mood logged successfully.\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:40:36.773588Z","iopub.execute_input":"2025-04-19T09:40:36.773856Z","iopub.status.idle":"2025-04-19T09:40:36.78456Z","shell.execute_reply.started":"2025-04-19T09:40:36.773836Z","shell.execute_reply":"2025-04-19T09:40:36.783498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# simulate adding past data to db\n### no need to run always\nmarch_1_data = {\n    \"mood_description\": \"Happy\",\n    \"emoji\": \"ðŸ˜€\",\n    \"quote\": \"A good day starts with a smile.\",\n    \"timestamp\": \"2025-03-01T10:00:00\"\n}\n\ndocument = f\"Mood: {march_1_data['mood_description']}\\nEmoji: {march_1_data['emoji']}\\nQuote: {march_1_data['quote']}\\nTimestamp: {march_1_data['timestamp']}\"\ndb.add(\n    documents=[document],\n    ids=[\"mood_log_2025-03-01T10:00:00\"]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T09:39:28.343379Z","iopub.execute_input":"2025-04-19T09:39:28.343724Z","iopub.status.idle":"2025-04-19T09:39:28.447946Z","shell.execute_reply.started":"2025-04-19T09:39:28.343697Z","shell.execute_reply":"2025-04-19T09:39:28.446429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tool\ndef query_mood_history_with_quote(query_details: str):\n    \"\"\"Queries the mood history from the diary based on the user's request using semantic search.\"\"\"\n    \n    result = db.query(\n        query_texts=[query_details],\n        n_results=5  # Adjust as needed\n    )\n    [all_passages] = result[\"documents\"]\n\n    \n    query_oneline = query_details.replace(\"\\n\", \" \")\n\n    # This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n    prompt = f\"\"\"You are a friendly and insightful journaling assistant. A user has asked about their past moods with the query: '{query_oneline}'.\n\n    Please consider the following when crafting your response:\n\n    * Acknowledge the user's query directly. Start by addressing what they asked.\n    * Synthesize the information: Don't just list the entries. Look for patterns, common themes, or changes in mood over the retrieved entries.\n    * Highlight key feelings and any associated quotes or events (if mentioned).\n    * Maintain a supportive and encouraging tone.\n    * Keep your language clear and easy to understand for a non-technical audience.\n    * If the retrieved entries seem irrelevant to the query, gently state that you couldn't find specific information related to that and perhaps suggest rephrasing.\n    * Your response should be formatted as a single string that can be easily used in subsequent steps of a Langchain flow.\n\n    --- Diary Entries ---\n    \n    \n    QUESTION: {query_oneline}\n    \"\"\"\n\n    # Add the retrieved documents to the prompt.\n    for passage in all_passages:\n        passage_oneline = passage.replace(\"\\n\", \" \")\n        prompt += f\"PASSAGE: {passage_oneline}\\n\"\n\n    answer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\n    return answer.text\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:30:22.287978Z","iopub.execute_input":"2025-04-19T05:30:22.288304Z","iopub.status.idle":"2025-04-19T05:30:22.298652Z","shell.execute_reply.started":"2025-04-19T05:30:22.288276Z","shell.execute_reply":"2025-04-19T05:30:22.297646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### to test the fuinction without the tool\n#query_mood_history_with_quote(\"past moods\")\n#query_mood_history_with_quote(\"all old moods\")\n#query_mood_history_with_quote(\"earlier this week\")\n#query_mood_history_with_quote(\"march 2025\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-15T20:02:22.339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### to test the function without tool\n\n#log_mood_with_quote(\n#        \"happy\",\n#        \"ðŸ˜Š\",\n#        \"Believe you can and you\\'re halfway there. - Theodore Roosevelt\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-15T20:02:22.339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### to make sure db write/read works\n\ndb.count()\ndb.peek()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:30:29.095124Z","iopub.execute_input":"2025-04-19T05:30:29.095941Z","iopub.status.idle":"2025-04-19T05:30:29.110014Z","shell.execute_reply.started":"2025-04-19T05:30:29.095912Z","shell.execute_reply":"2025-04-19T05:30:29.109322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define the tools and create a \"tools\" node.\ntools = [log_mood_with_quote, query_mood_history_with_quote]\ntool_node = ToolNode(tools)\n\n# Attach the tools to the model so that it knows what it can call.\nllm_with_tools = llm.bind_tools(tools)\n\n\ndef maybe_route_to_tools(state: DiaryBotState) -> Literal[\"tools\", \"human\"]:\n    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n    if not (msgs := state.get(\"messages\", [])):\n        raise ValueError(f\"No messages found when parsing state: {state}\")\n\n    # Only route based on the last message.\n    msg = msgs[-1]\n\n    # When the chatbot returns tool_calls, route to the \"tools\" node.\n    if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n        return \"tools\"\n    else:\n        return \"human\"\n\n\ndef chatbot_with_tools(state: DiaryBotState) -> DiaryBotState:\n    \"\"\"The chatbot with tools. A simple wrapper around the model's own chat interface.\"\"\"\n    defaults = {\"order\": [], \"finished\": False}\n\n    if state[\"messages\"]:\n        new_output = llm_with_tools.invoke([DIARYBOT_SYSINT] + state[\"messages\"])\n    else:\n        new_output = AIMessage(content=WELCOME_MSG)\n\n    # Set up some defaults if not already set, then pass through the provided state,\n    # overriding only the \"messages\" field.\n    return defaults | state | {\"messages\": [new_output]}\n\n\ndef maybe_exit_human_node(state: DiaryBotState) -> Literal[\"chatbot\", \"__end__\"]:\n    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n    if state.get(\"finished\", False):\n        return END\n    else:\n        return \"chatbot\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:31:20.390653Z","iopub.execute_input":"2025-04-19T05:31:20.391088Z","iopub.status.idle":"2025-04-19T05:31:20.406874Z","shell.execute_reply.started":"2025-04-19T05:31:20.391062Z","shell.execute_reply":"2025-04-19T05:31:20.405803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"graph_builder = StateGraph(DiaryBotState)\n\n# Add the nodes, including the new tool_node.\ngraph_builder.add_node(\"chatbot\", chatbot_with_tools)\ngraph_builder.add_node(\"human\", human_node)\ngraph_builder.add_node(\"tools\", tool_node)\n\n# Chatbot may go to tools, or human.\ngraph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n# Human may go back to chatbot, or exit.\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n\n# Tools always route back to chat afterwards.\ngraph_builder.add_edge(\"tools\", \"chatbot\")\n\ngraph_builder.add_edge(START, \"chatbot\")\ngraph_with_menu = graph_builder.compile()\n\nImage(graph_with_menu.get_graph().draw_mermaid_png())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:31:35.791001Z","iopub.execute_input":"2025-04-19T05:31:35.791332Z","iopub.status.idle":"2025-04-19T05:31:35.877588Z","shell.execute_reply.started":"2025-04-19T05:31:35.791307Z","shell.execute_reply":"2025-04-19T05:31:35.876459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = {\"recursion_limit\": 100}\nstate = graph_with_menu.invoke({\"messages\": []}, config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T05:31:43.787429Z","iopub.execute_input":"2025-04-19T05:31:43.787753Z","iopub.status.idle":"2025-04-19T05:32:24.693046Z","shell.execute_reply.started":"2025-04-19T05:31:43.787729Z","shell.execute_reply":"2025-04-19T05:32:24.692404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"state = graph_with_menu.invoke({\"messages\": []}, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T18:40:08.137476Z","iopub.execute_input":"2025-04-15T18:40:08.137787Z","iopub.status.idle":"2025-04-15T18:41:05.037346Z","shell.execute_reply.started":"2025-04-15T18:40:08.137764Z","shell.execute_reply":"2025-04-15T18:41:05.036711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### for debugging\n\n#from pprint import pprint\n#pprint(state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:39:57.866182Z","iopub.execute_input":"2025-04-15T17:39:57.866556Z","iopub.status.idle":"2025-04-15T17:39:57.870985Z","shell.execute_reply.started":"2025-04-15T17:39:57.866525Z","shell.execute_reply":"2025-04-15T17:39:57.870208Z"}},"outputs":[],"execution_count":null}]}